---
title: "Assignment 2 - Language Development in ASD - Part 1 - Explaining development"
author: "Studygroup 4"
date: "11/9/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(include = FALSE)
```

#CLEAN markdown with 
#small comments on choises and results are made along the way while the full report can be seen in the attached document.

[See the document here](https://docs.google.com/document/d/1LtrmpRjy1SYCNhrBuOoLZX5uBSWwxAVzhSJ664kV0XU/edit?usp=sharing)

**Loading usefull packages**

```{r, include = TRUE}
pacman::p_load(tidyverse, purrr, MuMIn, lmerTest)
```


**Loading the clean dataframe from last portfolio**

```{r Load Data, include = TRUE}
df<- read.csv("autism_df.csv")
#removing x 
df[,1] <- NULL
```

**Exploring Participants** 

```{r descriptive stats, include = TRUE}
#exploring the format of the variables
str(df)

#Mutating variables
df <- df %>% 
  mutate(SUBJ = as.factor(SUBJ),
         #VISIT = as.factor(VISIT),
         Gender = as.factor(Gender),
         Diagnosis = as.factor(Diagnosis),
         Ethnicity = as.factor(Ethnicity)
      ) 
#Checking the difference in each condition by "splitting"/grouping Td from ASD 
df %>%
  split(df$Diagnosis) %>%
  map(summary)

```

*REPORT IN DOCS*

# Hypothesis 1: The child's MLU changes: i) over time, ii) according to diagnosis

**Ploting the data**
```{r}
#Because visit doesn't makes sence as a factor we transform
df <- df %>% 
  mutate(VISIT = as.integer(VISIT))
```

```{r, include = TRUE}
#Plotting Mean length utterance for all visits for each diagnosis in linear
df %>%
  ggplot(aes(x = VISIT, y = CHI_MLU, color = Diagnosis)) +
    geom_point(stat='summary') + 
    geom_smooth(method = "lm") 

```

**Making a model**
Fixed effect: 
Random effect: 
To account for independence, *linear mixed-effects model* is used
```{r, include = TRUE}

#null model
null_model <- lmerTest::lmer(CHI_MLU ~ 1+(1|SUBJ),
                      df,
                     REML = FALSE)

summary(null_model)

m0 <- lmerTest::lmer(CHI_MLU ~ Gender + Age +(1+VISIT|SUBJ)+
                       VISIT*Diagnosis,
                      df,
                     REML = FALSE)
summary(m0)
#Age is highly correlated with visit. Therefore, it should be removed. 

m1 <- lmerTest::lmer(CHI_MLU ~ VISIT*Diagnosis+Gender+
                       (1+VISIT|SUBJ),
                      df,
                     REML = FALSE)
summary(m1)
# Gender has a high p -value. Let us try without it.

m2 <- lmerTest::lmer(CHI_MLU ~ VISIT*Diagnosis+
             (1+VISIT|SUBJ),
                      df,
                     REML = FALSE)
summary(m2)
# Only with the interaction effect

m3 <- lmerTest::lmer(CHI_MLU ~ VISIT+(1+VISIT|SUBJ),
                      df,
                     REML = FALSE)

summary(m3)
# VISIT as the only predictor



```

**Assessing the model**
```{r, include = TRUE}

anova(m1, m2, m3)
# m2 has the best AIC and BIC score. Furthermore, the anova tells us that m2 is significantly different from m3 whereas m1 is not significantly different. Therefore, we choose to exclude gender and stay with m2.



# How about the R squared value?
r.squaredGLMM(m1)
r.squaredGLMM(m2)
r.squaredGLMM(m3)


# We have chosen m2 as our model and now we want to see if this model is better than the null model
anova(m2, null_model)
```
Our model is significantly better than the null model. 

**Checking assumptions**
```{r}
plot(m2)
qqnorm(residuals(m2))

```


Doesn't seem too good yet

**Creating growth models**

*Visualizing  quadratic*
```{r, include = TRUE}
qplot(VISIT,CHI_MLU, data = df, color = Diagnosis)+stat_smooth(method="lm", formula="y~poly(x,2)")

```

**Quadratic model**
```{r, include = TRUE}
growth <- lmerTest::lmer(CHI_MLU ~ VISIT*Diagnosis+I(VISIT^2)+(1+I(VISIT^2)|SUBJ),
                      df,
                     REML = FALSE)
```

**Assesing the quadratic model** 
```{r}
plot(growth)
qqnorm(residuals(growth))
```




*Comparing models*
```{r, include = TRUE}
anova(m2, growth)
```

growth seems to be the best fit.

Plotting the actual CHI_MLU data against the predictions of the model fitted(model). 
```{r}
df2 <- df[!is.na(df$CHI_MLU), 1:20] 

ggplot(df2, aes(x=VISIT, y=CHI_MLU, color=Diagnosis)) +
  stat_summary(fun.data=mean_se, geom="point") + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.1) + 
  stat_summary(aes(y=predict(growth,df2,re.form=NA)), fun.y=mean, geom="line") +
  xlab('Visit') + ylab('Child MLU') + ggtitle('Actual data vs. model prediction values')
  
```


# Hypothesis 2: The parents's MLU changes: i) over time, ii) according to diagnosis

*Ploting the data*

```{r, include = TRUE}
#Plotting Mean length utterance for all visits for each diagnosis in linear
df %>%
  ggplot(aes(x = VISIT, y = MOT_MLU, color = Diagnosis)) +
    geom_point() + 
    geom_smooth(method = "lm") 
  
```

*Making a model*

```{r, include = TRUE}
#null model
mot_null <- lmerTest::lmer(MOT_MLU ~ 1+(1|SUBJ),
                      df,
                     REML = FALSE)

summary(mot_null)


mot_m1 <- lmerTest::lmer(MOT_MLU ~ VISIT*Diagnosis+
             (1+VISIT|SUBJ),
                      df,
                     REML = FALSE)
summary(mot_m1)
# Only with the interaction effect

mot_m2 <- lmerTest::lmer(MOT_MLU ~ VISIT+Diagnosis+
             (1+VISIT|SUBJ),
                      df,
                     REML = FALSE)

summary(mot_m2)
mot_m3 <- lmerTest::lmer(MOT_MLU ~ VISIT+(1+VISIT|SUBJ),
                      df,
                     REML = FALSE)

summary(mot_m3)
# VISIT as the only predictor

```

*Assessing the model*
```{r, include = TRUE}
anova(mot_null, mot_m1, mot_m2, mot_m3)

#Let us check r squared
r.squaredGLMM(mot_null)
r.squaredGLMM(mot_m1)
r.squaredGLMM(mot_m2)
r.squaredGLMM(mot_m3)
```
m2 is the best model when comparing AIC, BIC and logLik scores. 

**Checking the model** 
```{r}
plot(mot_m2)
qqnorm(residuals(mot_m2))
```

**Creating growth models**

*Visualizing quadratic*
```{r, include = TRUE}
qplot(VISIT,MOT_MLU, data = df, color = Diagnosis)+stat_smooth(method="lm", formula="y~poly(x,2)")
```

**Quadratic Model**
```{r, include = TRUE}
mot_growth <- lmerTest::lmer(MOT_MLU ~ Diagnosis+I(VISIT^2)+(1|SUBJ),
                      df,
                     REML = FALSE)

summary(mot_growth)
```
**Checking the quadratic model** 
```{r}
plot(mot_growth)
qqnorm(residuals(mot_growth))
```

*Comparing models*
```{r, include = TRUE}
anova(mot_m2, mot_growth)
```

m2 seems to be the best fit. When plotting this model agianst the actual data, it can be seen that their is a linear trend. 

```{r}

ggplot(df2, aes(x=VISIT, y=MOT_MLU, color=Diagnosis)) +
  stat_summary(fun.data=mean_se, geom="point") + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.1) + 
  stat_summary(aes(y=predict(mot_m2,df2,re.form=NA)), fun.y=mean, geom="line") +
  xlab('Visit') + ylab('Mother MLU') + ggtitle('Actual data vs. model prediction values')
```


- Excercise 4: Adding new variables
  *Your task now is to figure out how to best describe the children linguistic trajectory. The dataset contains a bunch of additional demographic, cognitive and clinical variables (e.g.verbal and non-verbal IQ). Try them out and identify the statistical models that best describes your data (that is, the children's MLU). Describe how you selected the best model and send the code to run the model to Victor and Byurakn.*

**Making models**  
```{r, include = TRUE}

#Modelling the 4 additional predictors individually to Child MLU to check which one makes sense to include 
bm1 <- lmer(CHI_MLU ~ Socialization1 + (1|SUBJ), df, REML = F)
summary(bm1)
r.squaredGLMM(bm1)
  #Socialization predicts okay 

bm2 <- lmer(CHI_MLU ~ ADOS1 + (1|SUBJ), df, REML = F)
summary(bm2)
r.squaredGLMM(bm2)
  #Not good

bm3 <- lmer(CHI_MLU ~ nonverbalIQ1 + (1|SUBJ), df, REML = F)
summary(bm3)
r.squaredGLMM(bm3)
  #Pretty good

bm4 <- lmer(CHI_MLU ~ verbalIQ1 + (1|SUBJ), df, REML = F)
summary(bm4)
r.squaredGLMM(bm4)
  #Pretty good 
```

*Plotting simple models*
```{r}
#Making plots to see if we should look for interactions for the predictors and diagnosis 

ggplot(df, aes(x=Socialization, y = CHI_MLU, color = Diagnosis))+
  geom_point()+
  geom_smooth(method = "lm")
  #Seems like an interaction? 

ggplot(df, aes(x=nonverbalIQ, y = CHI_MLU, color = Diagnosis))+
  geom_point()+
  geom_smooth(method = "lm")
  #No interaction 

ggplot(df, aes(x=verbalIQ, y = CHI_MLU, color = Diagnosis))+
  geom_point()+
  geom_smooth(method = "lm")
  #No interaction
```

*Making max-models*
```{r}
#Making a maxmodel with the previous reviewed model and adding predictors and interaction, and removing the random slope to adjust for complexity 

bmax <- lmer(CHI_MLU ~ I(VISIT^2)+VISIT*Diagnosis+ Socialization*Diagnosis + verbalIQ1 + nonverbalIQ1  +(1|SUBJ), df, REML = F)
summary(bmax)
  #Looking at the summary it seems like verbal and nonverbal IQ could explain some of the same variance 

#Checking which IQ measure to use 

  #Model with nonverbal
bmaxnv <- lmer(CHI_MLU ~ I(VISIT^2)+VISIT*Diagnosis+ Socialization*Diagnosis + nonverbalIQ1  +(1|SUBJ), df, REML = F)

  #Model with verbal
bmaxv <- lmer(CHI_MLU ~ I(VISIT^2)+VISIT*Diagnosis+ Socialization*Diagnosis + verbalIQ1+(1|SUBJ), df, REML = F)

anova(bmaxnv, bmaxv, bmax)
  #According to the anova, verbalIQ is the better predictor and it is better to leave out nonverbal

#Now checking to see whether interaction with socialization and diagnosis makes a good difference 

bmax1 <- lmer(CHI_MLU ~ I(VISIT^2)+VISIT*Diagnosis+ Socialization + verbalIQ1+(1|SUBJ), df, REML = F)

anova(bmaxv, bmax1)
  #According to the anova, the interaction makes a difference, with a lower AIC and higher logLik. But at this point we should be aware of overfitting the model. But since they wanted the model that best described the data, i would go with bmaxv model. Non of the predictors are highly correlated when looking at the correlation coeffecients and we have accounted for independence. 
summary(bmaxv)
```

*Checking assumptions*
```{r}

plot(bmaxv)
  #Homoschedasticity seems okay
qqnorm(residuals(bmaxv))
  #Normality of residuals seems okay too

```

Congrats! You made it to the end :D 

